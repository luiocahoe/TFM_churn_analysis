{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGBL5W_EZ4H0"
      },
      "source": [
        "<div style=\"width: 100%; clear: both;\">\n",
        "<div style=\"float: left; width: 50%;\">\n",
        "<img src=\"https://www.uoc.edu/content/dam/news/images/noticies/2016/202-nova-marca-uoc.jpg\" align=\"left\" width=\"45%\">\n",
        "</div>\n",
        "<div style=\"float: right; width: 50%;\">\n",
        "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">Trabajo de Fin de Máster</p>\n",
        "<p style=\"margin: 0; text-align:right;\">Máster universitario en Ciencia de datos (Data science)</p>\n",
        "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
        "</div>\n",
        "</div>\n",
        "<div style=\"width:100%;\">&nbsp;</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DA0-qN-Z4H0"
      },
      "source": [
        "# Machine Learning para predecir cancelaciones y mejorar la retención en seguros\n",
        "\n",
        "## Optimización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eDbVb5jhZ4H1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "X_test = pd.read_csv('X_test.csv')\n",
        "y_test = pd.read_csv('y_test.csv').squeeze()\n",
        "X_train_ros = pd.read_csv('X_train_ros.csv')\n",
        "y_train_ros = pd.read_csv('y_train_ros.csv').squeeze()\n",
        "X_train_rus = pd.read_csv('X_train_rus.csv')\n",
        "y_train_rus = pd.read_csv('y_train_rus.csv').squeeze()\n",
        "X_train_smote = pd.read_csv('X_train_smote.csv')\n",
        "y_train_smote = pd.read_csv('y_train_smote.csv').squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pEZ9yorCxnUq"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhC8TNpQZ4H1",
        "outputId": "09ece007-05f1-4398-b0c1-4d9b67ad9d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 13 candidates, totalling 26 fits\n",
            "\n",
            "Resultados para RandomUnderSampler (GaussianNB) con Hypertuning:\n",
            "Mejor hiperparámetro (var_smoothing): {'var_smoothing': 110}\n",
            "AUC: 0.6802\n",
            "F1-score: 0.2725\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.60      0.73    422179\n",
            "           1       0.17      0.65      0.27     54408\n",
            "\n",
            "    accuracy                           0.60    476587\n",
            "   macro avg       0.55      0.62      0.50    476587\n",
            "weighted avg       0.84      0.60      0.67    476587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Definimos el espacio de búsqueda para var_smoothing\n",
        "param_grid = {\n",
        "    'var_smoothing': [4e-1, 5e-1, 6e-1,7e-1, 8e-1, 9e-1,1 ,2, 10, 50, 100, 110, 115]\n",
        "}\n",
        "\n",
        "# Métrica principal a optimizar\n",
        "scorer = make_scorer(f1_score)\n",
        "\n",
        "# Configuramos la búsqueda en cuadrícula\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=GaussianNB(),\n",
        "    param_grid=param_grid,\n",
        "    scoring=scorer,\n",
        "    cv=2,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Ajustamos sobre los datos submuestreados\n",
        "grid_search.fit(X_train_rus, y_train_rus)\n",
        "\n",
        "# Extraemos el mejor modelo\n",
        "best_nb = grid_search.best_estimator_\n",
        "\n",
        "# Predicciones con el conjunto de test original\n",
        "y_pred_rus = best_nb.predict(X_test)\n",
        "y_proba_rus = best_nb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluación\n",
        "print(\"\\nResultados para RandomUnderSampler (GaussianNB) con Hypertuning:\")\n",
        "print(f\"Mejor hiperparámetro (var_smoothing): {grid_search.best_params_}\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_proba_rus):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_rus):.4f}\")\n",
        "print(classification_report(y_test, y_pred_rus))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xreJYiGAZ4H2",
        "outputId": "d10a5eb7-bb52-49b3-d15d-2151e1d54b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
            "\n",
            "Resultados para RandomUnderSampler (KNN) con Hypertuning:\n",
            "Mejores hiperparámetros: {'n_neighbors': 20, 'weights': 'distance'}\n",
            "AUC: 0.6798\n",
            "F1-score: 0.2994\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.70      0.80    422179\n",
            "           1       0.20      0.58      0.30     54408\n",
            "\n",
            "    accuracy                           0.69    476587\n",
            "   macro avg       0.57      0.64      0.55    476587\n",
            "weighted avg       0.85      0.69      0.74    476587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Definimos el espacio de búsqueda para los hiperparámetros\n",
        "param_grid = {\n",
        "    'n_neighbors': [10, 15, 20],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "}\n",
        "\n",
        "# Definimos la métrica principal para optimizar (F1 en este caso)\n",
        "scorer = make_scorer(f1_score)\n",
        "\n",
        "# Configuramos la búsqueda en cuadrícula\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=KNeighborsClassifier(),\n",
        "    param_grid=param_grid,\n",
        "    scoring=scorer,\n",
        "    cv=2,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Ejecutamos el ajuste sobre los datos submuestreados\n",
        "grid_search.fit(X_train_rus, y_train_rus)\n",
        "\n",
        "# Extraemos el mejor modelo\n",
        "best_knn = grid_search.best_estimator_\n",
        "\n",
        "# Predicciones con el conjunto de test original\n",
        "y_pred_rus = best_knn.predict(X_test)\n",
        "y_proba_rus = best_knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluación\n",
        "print(\"\\nResultados para RandomUnderSampler (KNN) con Hypertuning:\")\n",
        "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_proba_rus):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_rus):.4f}\")\n",
        "print(classification_report(y_test, y_pred_rus))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qr9NcazZ4H3",
        "outputId": "e3cb7538-9278-451b-c5e6-cefc2a2483f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
            "\n",
            "Resultados para SMOTE (Decision Tree) con Hypertuning:\n",
            "Mejores hiperparámetros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 2}\n",
            "AUC: 0.6524\n",
            "F1-score: 0.3963\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93    422179\n",
            "           1       0.46      0.35      0.40     54408\n",
            "\n",
            "    accuracy                           0.88    476587\n",
            "   macro avg       0.69      0.65      0.66    476587\n",
            "weighted avg       0.87      0.88      0.87    476587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Definimos el espacio de búsqueda\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "}\n",
        "\n",
        "# Métrica objetivo: F1\n",
        "scorer = make_scorer(f1_score)\n",
        "\n",
        "# Búsqueda con validación cruzada\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring=scorer,\n",
        "    cv=2,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Ajuste con datos SMOTE\n",
        "grid_search.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Mejor modelo\n",
        "best_dt = grid_search.best_estimator_\n",
        "\n",
        "# Predicción en test original\n",
        "y_pred_smote = best_dt.predict(X_test)\n",
        "y_proba_smote = best_dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluación\n",
        "print(\"\\nResultados para SMOTE (Decision Tree) con Hypertuning:\")\n",
        "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_proba_smote):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_smote):.4f}\")\n",
        "print(classification_report(y_test, y_pred_smote))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "nN8sRlqHZ4H3",
        "outputId": "77a6b89d-f182-4ac6-fbee-7d09eb3fb07d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
            "\n",
            "Resultados para SMOTE (Random Forest) con Hypertuning:\n",
            "Mejores hiperparámetros: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "AUC: 0.6937\n",
            "F1-score: 0.4533\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93    422179\n",
            "           1       0.46      0.45      0.45     54408\n",
            "\n",
            "    accuracy                           0.88    476587\n",
            "   macro avg       0.69      0.69      0.69    476587\n",
            "weighted avg       0.88      0.88      0.88    476587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Definimos el espacio de búsqueda para los hiperparámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [5, 10],\n",
        "    'min_samples_leaf': [2, 4],\n",
        "}\n",
        "\n",
        "# Definimos el scorer para optimizar el F1-score\n",
        "scorer = make_scorer(f1_score)\n",
        "\n",
        "# Configuramos la búsqueda en cuadrícula\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    param_grid=param_grid,\n",
        "    scoring=scorer,\n",
        "    cv=2,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Ajustamos el modelo con los datos de SMOTE\n",
        "grid_search.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Extraemos el mejor modelo\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Predicciones sobre el conjunto de prueba\n",
        "y_pred_smote = best_rf.predict(X_test)\n",
        "y_proba_smote = best_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluación\n",
        "print(\"\\nResultados para SMOTE (Random Forest) con Hypertuning:\")\n",
        "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_proba_smote):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_smote):.4f}\")\n",
        "print(classification_report(y_test, y_pred_smote))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VaPdJjnUZ4H3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
            "\n",
            "Resultados para RandomOverSampler (AdaBoost) con Hypertuning:\n",
            "Mejores hiperparámetros: {'learning_rate': 1, 'n_estimators': 250}\n",
            "AUC: 0.6946\n",
            "F1-score: 0.4114\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.89      0.91    422179\n",
            "           1       0.36      0.48      0.41     54408\n",
            "\n",
            "    accuracy                           0.84    476587\n",
            "   macro avg       0.65      0.68      0.66    476587\n",
            "weighted avg       0.86      0.84      0.85    476587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Definimos el espacio de búsqueda para los hiperparámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [150, 200, 250],\n",
        "    'learning_rate': [0.01, 0.1, 0.5, 1],\n",
        "}\n",
        "\n",
        "# Configuramos la búsqueda en cuadrícula\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=AdaBoostClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1',  # Utilizamos F1-score como métrica\n",
        "    cv=2,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Ajustamos el modelo con los datos sobre muestreo RandomOverSampler\n",
        "grid_search.fit(X_train_ros, y_train_ros)\n",
        "\n",
        "# Extraemos el mejor modelo\n",
        "best_ada = grid_search.best_estimator_\n",
        "\n",
        "# Predicciones sobre el conjunto de prueba\n",
        "y_pred_ros = best_ada.predict(X_test)\n",
        "y_proba_ros = best_ada.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluación\n",
        "print(\"\\nResultados para RandomOverSampler (AdaBoost) con Hypertuning:\")\n",
        "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_proba_ros):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_ros):.4f}\")\n",
        "print(classification_report(y_test, y_pred_ros))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OHoj68xYZ4H4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 144 candidates, totalling 288 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "python(2722) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(2957) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(3031) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(4135) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(4228) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(5210) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7435) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7682) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8345) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8668) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(48964) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 24\u001b[0m\n\u001b[1;32m     14\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     15\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mXGBClassifier(eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     16\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Ajustamos el modelo con los datos sobre muestreo RandomOverSampler\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_ros, y_train_ros)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Extraemos el mejor modelo\u001b[39;00m\n\u001b[1;32m     27\u001b[0m best_xgb \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    966\u001b[0m         clone(base_estimator),\n\u001b[1;32m    967\u001b[0m         X,\n\u001b[1;32m    968\u001b[0m         y,\n\u001b[1;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    975\u001b[0m     )\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m )\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Definimos el espacio de búsqueda para los hiperparámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [300, 400, 500],\n",
        "    'learning_rate': [0.001, 0.1, 0.5, 0.82],\n",
        "    'max_depth': [30, 40, 50, 60],\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Configuramos la búsqueda en cuadrícula\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=XGBClassifier(eval_metric='logloss', random_state=42, n_jobs=-1),\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1',  # Utilizamos F1-score como métrica\n",
        "    cv=2,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Ajustamos el modelo con los datos sobre muestreo RandomOverSampler\n",
        "grid_search.fit(X_train_ros, y_train_ros)\n",
        "\n",
        "# Extraemos el mejor modelo\n",
        "best_xgb = grid_search.best_estimator_\n",
        "\n",
        "# Predicciones sobre el conjunto de prueba\n",
        "y_pred_ros = best_xgb.predict(X_test)\n",
        "y_proba_ros = best_xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluación\n",
        "print(\"\\nResultados para RandomOverSampler (XGBoost) con Hypertuning:\")\n",
        "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_proba_ros):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_ros):.4f}\")\n",
        "print(classification_report(y_test, y_pred_ros))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 04:43:28,334] A new study created in memory with name: no-name-19a82484-c0f0-41e0-873f-1015a930d84d\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 220us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 05:01:22,823] Trial 0 finished with value: 0.6425449061790138 and parameters: {'units1': 250, 'dropout1': 0.2638138735924608, 'units2': 105, 'dropout2': 0.20603272797717542, 'lr': 0.00010616166714444989, 'batch_size': 128}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 216us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 05:05:01,726] Trial 1 finished with value: 0.6221388343701675 and parameters: {'units1': 226, 'dropout1': 0.4451994247393244, 'units2': 38, 'dropout2': 0.18472860447750317, 'lr': 0.006541503635203153, 'batch_size': 256}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 05:15:43,576] Trial 2 finished with value: 0.6243790307132369 and parameters: {'units1': 252, 'dropout1': 0.35089789588140224, 'units2': 111, 'dropout2': 0.3735930543796355, 'lr': 0.0022073460299882933, 'batch_size': 64}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 05:27:29,146] Trial 3 finished with value: 0.6221830340047176 and parameters: {'units1': 72, 'dropout1': 0.46587506196038464, 'units2': 104, 'dropout2': 0.19882690144761161, 'lr': 0.0013328628673386434, 'batch_size': 64}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 05:38:08,218] Trial 4 finished with value: 0.6255495668728571 and parameters: {'units1': 143, 'dropout1': 0.3120886114407305, 'units2': 99, 'dropout2': 0.15692590295551972, 'lr': 0.00255393468574977, 'batch_size': 64}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 05:41:02,674] Trial 5 finished with value: 0.619456021972169 and parameters: {'units1': 159, 'dropout1': 0.5684978027714169, 'units2': 69, 'dropout2': 0.2623350209726344, 'lr': 0.006367037747712347, 'batch_size': 256}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 05:45:57,084] Trial 6 finished with value: 0.6221076890038494 and parameters: {'units1': 237, 'dropout1': 0.383201864972257, 'units2': 41, 'dropout2': 0.36164176101218937, 'lr': 0.005127822008945567, 'batch_size': 128}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 05:49:25,034] Trial 7 finished with value: 0.6127210897522762 and parameters: {'units1': 106, 'dropout1': 0.5784196078457041, 'units2': 61, 'dropout2': 0.33412283297446016, 'lr': 0.0051812499875424686, 'batch_size': 64}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 05:52:33,910] Trial 8 finished with value: 0.6204241998338976 and parameters: {'units1': 167, 'dropout1': 0.46531940274539607, 'units2': 43, 'dropout2': 0.2021331214032452, 'lr': 0.0064875457269252205, 'batch_size': 128}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 05:57:29,176] Trial 9 finished with value: 0.6231941370446673 and parameters: {'units1': 114, 'dropout1': 0.35749362993973616, 'units2': 39, 'dropout2': 0.19349896273199185, 'lr': 0.004837287429183998, 'batch_size': 64}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 06:03:36,278] Trial 10 finished with value: 0.622012481898684 and parameters: {'units1': 203, 'dropout1': 0.2147240820305069, 'units2': 127, 'dropout2': 0.27968390073719085, 'lr': 0.00944643513348476, 'batch_size': 128}. Best is trial 0 with value: 0.6425449061790138.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 06:15:51,227] Trial 11 finished with value: 0.6504044051670671 and parameters: {'units1': 168, 'dropout1': 0.24973073484818603, 'units2': 96, 'dropout2': 0.10410885353946545, 'lr': 0.00024227513354465252, 'batch_size': 128}. Best is trial 11 with value: 0.6504044051670671.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 06:31:39,536] Trial 12 finished with value: 0.6887561824949536 and parameters: {'units1': 194, 'dropout1': 0.20363739980422105, 'units2': 87, 'dropout2': 0.11754454723046401, 'lr': 0.0002526691869671853, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 223us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 06:44:10,323] Trial 13 finished with value: 0.6636097872327614 and parameters: {'units1': 195, 'dropout1': 0.2011484686104915, 'units2': 85, 'dropout2': 0.10073289334763282, 'lr': 0.00035536623862614974, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 06:53:52,790] Trial 14 finished with value: 0.6274368231046932 and parameters: {'units1': 182, 'dropout1': 0.20000785164040932, 'units2': 85, 'dropout2': 0.11630853959575356, 'lr': 0.0032804340663020255, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 07:08:27,364] Trial 15 finished with value: 0.6403763285039541 and parameters: {'units1': 203, 'dropout1': 0.283724180623677, 'units2': 80, 'dropout2': 0.13880552107242977, 'lr': 0.001109082829638066, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 07:15:01,567] Trial 16 finished with value: 0.6252757602362519 and parameters: {'units1': 206, 'dropout1': 0.3110745416684445, 'units2': 59, 'dropout2': 0.14585173484897188, 'lr': 0.0035226259417244026, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 07:19:22,554] Trial 17 finished with value: 0.6233245983675533 and parameters: {'units1': 135, 'dropout1': 0.23464874041897668, 'units2': 84, 'dropout2': 0.10212576177942878, 'lr': 0.008885703528533816, 'batch_size': 256}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 07:31:43,172] Trial 18 finished with value: 0.6345173967705058 and parameters: {'units1': 187, 'dropout1': 0.5282165155649579, 'units2': 73, 'dropout2': 0.2370332367027376, 'lr': 0.0012025262458929013, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 221us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 07:43:20,120] Trial 19 finished with value: 0.6281565048867669 and parameters: {'units1': 223, 'dropout1': 0.29803809459598823, 'units2': 120, 'dropout2': 0.2909790980734309, 'lr': 0.0020887543077334034, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 216us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 07:48:58,797] Trial 20 finished with value: 0.6248832948299211 and parameters: {'units1': 216, 'dropout1': 0.20479091189211407, 'units2': 93, 'dropout2': 0.16208279644878454, 'lr': 0.007941610254918014, 'batch_size': 256}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 07:58:44,800] Trial 21 finished with value: 0.6433904106320916 and parameters: {'units1': 177, 'dropout1': 0.2541901954738812, 'units2': 93, 'dropout2': 0.10097985054654608, 'lr': 0.0003509765189697649, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 08:14:50,137] Trial 22 finished with value: 0.6386153520883119 and parameters: {'units1': 152, 'dropout1': 0.24162218339982933, 'units2': 92, 'dropout2': 0.12831864427007655, 'lr': 0.00017346384769260768, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 08:28:12,523] Trial 23 finished with value: 0.6354069977001815 and parameters: {'units1': 196, 'dropout1': 0.2662378588340079, 'units2': 71, 'dropout2': 0.1669809803810584, 'lr': 0.0011124565624082347, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 08:42:22,400] Trial 24 finished with value: 0.629511473267479 and parameters: {'units1': 166, 'dropout1': 0.23090130396833522, 'units2': 114, 'dropout2': 0.12246956123879757, 'lr': 0.0033314744013472055, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 08:53:31,229] Trial 25 finished with value: 0.6266008026379692 and parameters: {'units1': 117, 'dropout1': 0.34608812546844925, 'units2': 88, 'dropout2': 0.22955462228969054, 'lr': 0.0018212080528347279, 'batch_size': 128}. Best is trial 12 with value: 0.6887561824949536.\n",
            "[W 2025-05-06 09:05:11,687] Trial 26 failed with parameters: {'units1': 181, 'dropout1': 0.20180740177426942, 'units2': 77, 'dropout2': 0.1307805246966578, 'lr': 0.0009135089099540973, 'batch_size': 128} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/var/folders/c9/t4s6bts95ybb23rnpkn7kc100000gn/T/ipykernel_2241/1178642045.py\", line 35, in objective\n",
            "    history = model.fit(\n",
            "              ^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
            "    logs = self.train_function(iterator)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
            "    opt_outputs = multi_step_on_iterator(iterator)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
            "    results = tracing_compilation.call_function(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
            "    return function._call_flat(  # pylint: disable=protected-access\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
            "    return self._inference_function.call_preflattened(args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
            "    flat_outputs = self.call_flat(*args)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
            "    outputs = self._bound_context.call_function(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py\", line 1688, in call_function\n",
            "    outputs = execute.execute(\n",
            "              ^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/luisocanahober/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[W 2025-05-06 09:05:11,698] Trial 26 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1_score(y_val, y_pred)\n\u001b[1;32m     48\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[1;32m     63\u001b[0m             study,\n\u001b[1;32m     64\u001b[0m             func,\n\u001b[1;32m     65\u001b[0m             n_trials,\n\u001b[1;32m     66\u001b[0m             timeout,\n\u001b[1;32m     67\u001b[0m             catch,\n\u001b[1;32m     68\u001b[0m             callbacks,\n\u001b[1;32m     69\u001b[0m             gc_after_trial,\n\u001b[1;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     73\u001b[0m         )\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[0;32mIn[5], line 35\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     27\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m     28\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Entrenamiento con early stopping\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     36\u001b[0m     X_train_final, y_train_final,\n\u001b[1;32m     37\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[1;32m     38\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     39\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m]),\n\u001b[1;32m     40\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     41\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Cálculo de F1 score\u001b[39;00m\n\u001b[1;32m     45\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (model\u001b[38;5;241m.\u001b[39mpredict(X_val) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1689\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1690\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1691\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1692\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1693\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1694\u001b[0m   )\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import optuna\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# División estratificada para validación\n",
        "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
        "    X_train_smote, y_train_smote, test_size=0.2, random_state=42, stratify=y_train_smote\n",
        ")\n",
        "\n",
        "def objective(trial):\n",
        "    # Arquitectura de red\n",
        "    model = Sequential([\n",
        "        Input(shape=(X_train_final.shape[1],)),\n",
        "        Dense(trial.suggest_int('units1', 64, 256), activation='relu'),\n",
        "        Dropout(trial.suggest_float('dropout1', 0.2, 0.6)),\n",
        "        Dense(trial.suggest_int('units2', 32, 128), activation='relu'),\n",
        "        Dropout(trial.suggest_float('dropout2', 0.1, 0.4)),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    # Optimización de hiperparámetros\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=trial.suggest_float('lr', 1e-4, 1e-2)\n",
        "        ),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    # Entrenamiento con early stopping\n",
        "    history = model.fit(\n",
        "        X_train_final, y_train_final,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=trial.suggest_categorical('batch_size', [64, 128, 256]),\n",
        "        verbose=0,\n",
        "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "    )\n",
        "    \n",
        "    # Cálculo de F1 score\n",
        "    y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
        "    return f1_score(y_val, y_pred)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14894/14894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205us/step\n",
            "\u001b[1m14894/14894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205us/step\n",
            "\n",
            "Resultados para el modelo neuronal (Optuna + SMOTE):\n",
            "Mejores hiperparámetros: {'units1': 117, 'dropout1': 0.34608812546844925, 'units2': 88, 'dropout2': 0.22955462228969054, 'lr': 0.0018212080528347279, 'batch_size': 128}\n",
            "AUC: 0.6923\n",
            "F1-score: 0.4302\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92    422179\n",
            "           1       0.40      0.46      0.43     54408\n",
            "\n",
            "    accuracy                           0.86    476587\n",
            "   macro avg       0.67      0.69      0.68    476587\n",
            "weighted avg       0.87      0.86      0.86    476587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Recuperar los mejores hiperparámetros\n",
        "best_params = {\n",
        "    'units1': 117,\n",
        "    'dropout1': 0.34608812546844925,\n",
        "    'units2': 88,\n",
        "    'dropout2': 0.22955462228969054,\n",
        "    'lr': 0.0018212080528347279,\n",
        "    'batch_size': 128\n",
        "}\n",
        "\n",
        "# Reconstruir el modelo con los hiperparámetros óptimos\n",
        "final_model = Sequential([\n",
        "    Input(shape=(X_train_smote.shape[1],)),\n",
        "    Dense(best_params['units1'], activation='relu'),\n",
        "    Dropout(best_params['dropout1']),\n",
        "    Dense(best_params['units2'], activation='relu'),\n",
        "    Dropout(best_params['dropout2']),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=best_params['lr'])\n",
        "final_model.compile(optimizer=optimizer,\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Ajuste del modelo\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "final_model.fit(\n",
        "    X_train_final, y_train_final,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=best_params['batch_size'],\n",
        "    callbacks=[early_stop],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
        "\n",
        "# Predicciones finales sobre el conjunto de prueba\n",
        "y_pred_test = (final_model.predict(X_test) > 0.5).astype(int).flatten()\n",
        "y_proba_test = final_model.predict(X_test).flatten()\n",
        "\n",
        "# Métricas de evaluación\n",
        "print(\"\\nResultados para el modelo neuronal (Optuna + SMOTE):\")\n",
        "print(f\"Mejores hiperparámetros: {best_params}\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_test):.4f}\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Definir la función de objetivo para Optuna\n",
        "def objective(trial):\n",
        "    # Definir el espacio de búsqueda de hiperparámetros\n",
        "    n_neurons_1 = trial.suggest_int('n_neurons_1', 32, 128)  # Neuronas en la primera capa\n",
        "    n_neurons_2 = trial.suggest_int('n_neurons_2', 16, 64)   # Neuronas en la segunda capa\n",
        "    dropout_1 = trial.suggest_float('dropout_1', 0.1, 0.5)    # Tasa de Dropout en la primera capa\n",
        "    dropout_2 = trial.suggest_float('dropout_2', 0.1, 0.5)    # Tasa de Dropout en la segunda capa\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
        "\n",
        "    # Crear el modelo\n",
        "    model = Sequential([\n",
        "        Input(shape=(X_train_ros.shape[1],)),\n",
        "        Dense(n_neurons_1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_1),\n",
        "        Dense(n_neurons_2, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compilar el modelo con la tasa de aprendizaje elegida\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "    # Definir los callbacks\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
        "\n",
        "    # Dividir los datos para entrenamiento y validación\n",
        "    X_ros_train, X_ros_val, y_ros_train, y_ros_val = train_test_split(\n",
        "        X_train_ros, y_train_ros, test_size=0.2, stratify=y_train_ros, random_state=42\n",
        "    )\n",
        "\n",
        "    # Entrenamiento del modelo\n",
        "    history = model.fit(X_ros_train, y_ros_train,\n",
        "                        validation_data=(X_ros_val, y_ros_val),\n",
        "                        epochs=100,\n",
        "                        batch_size=256,\n",
        "                        callbacks=[early_stop, reduce_lr],\n",
        "                        verbose=0)\n",
        "\n",
        "    # Evaluar el modelo con F1-score\n",
        "    y_pred_ros_nn = model.predict(X_ros_val).ravel()\n",
        "    y_pred_class = (y_pred_ros_nn >= 0.5).astype(int)  # Convertir probabilidades en predicciones binarias\n",
        "\n",
        "    f1 = f1_score(y_ros_val, y_pred_class)\n",
        "    \n",
        "    # Se retorna el F1-score como métrica de optimización\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 21:57:20,622] A new study created in memory with name: no-name-36b8ed2e-f65c-4b04-a1eb-94a7aa6d6013\n",
            "/var/folders/5w/3ld8z599699cd303197k9s9r0000gn/T/ipykernel_10680/52109843.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004060380626469851.\n",
            "\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 8.120761485770346e-05.\n",
            "\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.62415235536173e-05.\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 3.24830471072346e-06.\n",
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 22:00:46,508] Trial 0 finished with value: 0.6001143503019046 and parameters: {'n_neurons_1': 66, 'n_neurons_2': 50, 'dropout_1': 0.30444220193205873, 'dropout_2': 0.14072033584312837, 'learning_rate': 0.0020301903765699352}. Best is trial 0 with value: 0.6001143503019046.\n",
            "/var/folders/5w/3ld8z599699cd303197k9s9r0000gn/T/ipykernel_10680/52109843.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 2.3777037858963014e-05.\n",
            "\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 4.755407644552179e-06.\n",
            "\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 22:04:00,544] Trial 1 finished with value: 0.6003167031335213 and parameters: {'n_neurons_1': 46, 'n_neurons_2': 57, 'dropout_1': 0.433285768290593, 'dropout_2': 0.447831136640483, 'learning_rate': 0.0001188851883982773}. Best is trial 1 with value: 0.6003167031335213.\n",
            "/var/folders/5w/3ld8z599699cd303197k9s9r0000gn/T/ipykernel_10680/52109843.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00041863122023642066.\n",
            "\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 8.372624288313092e-05.\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.6745248285587876e-05.\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 3.349049802636728e-06.\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 22:07:11,936] Trial 2 finished with value: 0.5995459337274743 and parameters: {'n_neurons_1': 50, 'n_neurons_2': 51, 'dropout_1': 0.42880329092907, 'dropout_2': 0.26134519550236485, 'learning_rate': 0.002093156210604909}. Best is trial 1 with value: 0.6003167031335213.\n",
            "/var/folders/5w/3ld8z599699cd303197k9s9r0000gn/T/ipykernel_10680/52109843.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00028527444228529933.\n",
            "\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 5.705488729290664e-05.\n",
            "\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.1410977458581329e-05.\n",
            "\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 2.2821954189566895e-06.\n",
            "\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 22:12:30,099] Trial 3 finished with value: 0.5990592462699678 and parameters: {'n_neurons_1': 86, 'n_neurons_2': 49, 'dropout_1': 0.4008048480719718, 'dropout_2': 0.424792532347314, 'learning_rate': 0.0014263721712105047}. Best is trial 1 with value: 0.6003167031335213.\n",
            "/var/folders/5w/3ld8z599699cd303197k9s9r0000gn/T/ipykernel_10680/52109843.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.2674160825554282e-05.\n",
            "\n",
            "Epoch 69: ReduceLROnPlateau reducing learning rate to 2.5348321287310686e-06.\n",
            "\n",
            "Epoch 78: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 22:19:17,476] Trial 4 finished with value: 0.598895577334461 and parameters: {'n_neurons_1': 69, 'n_neurons_2': 56, 'dropout_1': 0.21670007384075382, 'dropout_2': 0.20684365112919087, 'learning_rate': 6.337080554218237e-05}. Best is trial 1 with value: 0.6003167031335213.\n",
            "/var/folders/5w/3ld8z599699cd303197k9s9r0000gn/T/ipykernel_10680/52109843.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 89: ReduceLROnPlateau reducing learning rate to 2.575485450506676e-06.\n",
            "\n",
            "Epoch 96: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 22:27:54,930] Trial 5 finished with value: 0.6002767158678846 and parameters: {'n_neurons_1': 105, 'n_neurons_2': 54, 'dropout_1': 0.20332625668450183, 'dropout_2': 0.34732467847616955, 'learning_rate': 1.2877426958349146e-05}. Best is trial 1 with value: 0.6003167031335213.\n",
            "/var/folders/5w/3ld8z599699cd303197k9s9r0000gn/T/ipykernel_10680/52109843.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.1977765825577081e-05.\n",
            "\n",
            "Epoch 93: ReduceLROnPlateau reducing learning rate to 2.395553201495204e-06.\n",
            "\n",
            "Epoch 98: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 22:33:52,251] Trial 6 finished with value: 0.5986155724866601 and parameters: {'n_neurons_1': 52, 'n_neurons_2': 40, 'dropout_1': 0.27610470657752906, 'dropout_2': 0.34652364211016917, 'learning_rate': 5.988883028304895e-05}. Best is trial 1 with value: 0.6003167031335213.\n",
            "/var/folders/5w/3ld8z599699cd303197k9s9r0000gn/T/ipykernel_10680/52109843.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 7.338767172768713e-05.\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.4677534636575729e-05.\n",
            "\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 2.9355069273151457e-06.\n",
            "\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 22:39:13,148] Trial 7 finished with value: 0.5991542414063226 and parameters: {'n_neurons_1': 76, 'n_neurons_2': 46, 'dropout_1': 0.2370409300380798, 'dropout_2': 0.17732141376058236, 'learning_rate': 0.00036693836271725703}. Best is trial 1 with value: 0.6003167031335213.\n",
            "/var/folders/5w/3ld8z599699cd303197k9s9r0000gn/T/ipykernel_10680/52109843.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 96: ReduceLROnPlateau reducing learning rate to 5.621584205073305e-06.\n",
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 22:45:09,507] Trial 8 finished with value: 0.5999334622365253 and parameters: {'n_neurons_1': 72, 'n_neurons_2': 21, 'dropout_1': 0.1600627802915284, 'dropout_2': 0.265430451847538, 'learning_rate': 2.810792065892616e-05}. Best is trial 1 with value: 0.6003167031335213.\n",
            "/var/folders/5w/3ld8z599699cd303197k9s9r0000gn/T/ipykernel_10680/52109843.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010319027351215483.\n",
            "\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 2.063805441139266e-05.\n",
            "\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 4.1276107367593795e-06.\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m12314/12314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-14 22:49:35,994] Trial 9 finished with value: 0.5990216399966836 and parameters: {'n_neurons_1': 63, 'n_neurons_2': 53, 'dropout_1': 0.16779733045276513, 'dropout_2': 0.2808276788160956, 'learning_rate': 0.0005159513634286087}. Best is trial 1 with value: 0.6003167031335213.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores hiperparámetros: {'n_neurons_1': 46, 'n_neurons_2': 57, 'dropout_1': 0.433285768290593, 'dropout_2': 0.447831136640483, 'learning_rate': 0.0001188851883982773}\n"
          ]
        }
      ],
      "source": [
        "# Crear el estudio de Optuna\n",
        "study = optuna.create_study(direction='maximize')  # Queremos maximizar el F1-score\n",
        "study.optimize(objective, n_trials=10)  # Realiza 10 intentos\n",
        "\n",
        "# Mostrar los mejores hiperparámetros\n",
        "print(f\"Mejores hiperparámetros: {study.best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 590us/step - accuracy: 0.5962 - loss: 0.7353 - val_accuracy: 0.6759 - val_loss: 0.6041 - learning_rate: 1.1889e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 558us/step - accuracy: 0.6756 - loss: 0.6124 - val_accuracy: 0.6858 - val_loss: 0.5951 - learning_rate: 1.1889e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 603us/step - accuracy: 0.6841 - loss: 0.6027 - val_accuracy: 0.6870 - val_loss: 0.5933 - learning_rate: 1.1889e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 605us/step - accuracy: 0.6855 - loss: 0.5994 - val_accuracy: 0.6876 - val_loss: 0.5924 - learning_rate: 1.1889e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 599us/step - accuracy: 0.6857 - loss: 0.5985 - val_accuracy: 0.6880 - val_loss: 0.5921 - learning_rate: 1.1889e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 557us/step - accuracy: 0.6855 - loss: 0.5978 - val_accuracy: 0.6882 - val_loss: 0.5911 - learning_rate: 1.1889e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 594us/step - accuracy: 0.6869 - loss: 0.5964 - val_accuracy: 0.6885 - val_loss: 0.5906 - learning_rate: 1.1889e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 597us/step - accuracy: 0.6868 - loss: 0.5960 - val_accuracy: 0.6887 - val_loss: 0.5905 - learning_rate: 1.1889e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 604us/step - accuracy: 0.6870 - loss: 0.5954 - val_accuracy: 0.6890 - val_loss: 0.5898 - learning_rate: 1.1889e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 599us/step - accuracy: 0.6867 - loss: 0.5953 - val_accuracy: 0.6895 - val_loss: 0.5894 - learning_rate: 1.1889e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 618us/step - accuracy: 0.6870 - loss: 0.5951 - val_accuracy: 0.6894 - val_loss: 0.5892 - learning_rate: 1.1889e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 624us/step - accuracy: 0.6878 - loss: 0.5942 - val_accuracy: 0.6897 - val_loss: 0.5889 - learning_rate: 1.1889e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 616us/step - accuracy: 0.6886 - loss: 0.5935 - val_accuracy: 0.6903 - val_loss: 0.5888 - learning_rate: 1.1889e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 616us/step - accuracy: 0.6883 - loss: 0.5933 - val_accuracy: 0.6903 - val_loss: 0.5881 - learning_rate: 1.1889e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 609us/step - accuracy: 0.6888 - loss: 0.5932 - val_accuracy: 0.6902 - val_loss: 0.5883 - learning_rate: 1.1889e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 573us/step - accuracy: 0.6886 - loss: 0.5930 - val_accuracy: 0.6905 - val_loss: 0.5880 - learning_rate: 1.1889e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 576us/step - accuracy: 0.6887 - loss: 0.5933 - val_accuracy: 0.6906 - val_loss: 0.5881 - learning_rate: 1.1889e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 638us/step - accuracy: 0.6891 - loss: 0.5931 - val_accuracy: 0.6907 - val_loss: 0.5877 - learning_rate: 1.1889e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 655us/step - accuracy: 0.6894 - loss: 0.5926 - val_accuracy: 0.6907 - val_loss: 0.5878 - learning_rate: 1.1889e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 643us/step - accuracy: 0.6887 - loss: 0.5932 - val_accuracy: 0.6913 - val_loss: 0.5883 - learning_rate: 1.1889e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 610us/step - accuracy: 0.6888 - loss: 0.5930 - val_accuracy: 0.6909 - val_loss: 0.5877 - learning_rate: 1.1889e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 601us/step - accuracy: 0.6894 - loss: 0.5926 - val_accuracy: 0.6912 - val_loss: 0.5876 - learning_rate: 1.1889e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m7624/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.6890 - loss: 0.5929\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.3777037858963014e-05.\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 553us/step - accuracy: 0.6890 - loss: 0.5929 - val_accuracy: 0.6912 - val_loss: 0.5878 - learning_rate: 1.1889e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 656us/step - accuracy: 0.6894 - loss: 0.5923 - val_accuracy: 0.6910 - val_loss: 0.5874 - learning_rate: 2.3777e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 579us/step - accuracy: 0.6896 - loss: 0.5919 - val_accuracy: 0.6910 - val_loss: 0.5872 - learning_rate: 2.3777e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 578us/step - accuracy: 0.6895 - loss: 0.5917 - val_accuracy: 0.6910 - val_loss: 0.5873 - learning_rate: 2.3777e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 569us/step - accuracy: 0.6897 - loss: 0.5922 - val_accuracy: 0.6911 - val_loss: 0.5872 - learning_rate: 2.3777e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 590us/step - accuracy: 0.6888 - loss: 0.5926 - val_accuracy: 0.6912 - val_loss: 0.5873 - learning_rate: 2.3777e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 581us/step - accuracy: 0.6893 - loss: 0.5924 - val_accuracy: 0.6909 - val_loss: 0.5872 - learning_rate: 2.3777e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m7664/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6895 - loss: 0.5922\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.755407644552179e-06.\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 589us/step - accuracy: 0.6895 - loss: 0.5922 - val_accuracy: 0.6911 - val_loss: 0.5872 - learning_rate: 2.3777e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 580us/step - accuracy: 0.6899 - loss: 0.5914 - val_accuracy: 0.6911 - val_loss: 0.5872 - learning_rate: 4.7554e-06\n",
            "Epoch 32/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 591us/step - accuracy: 0.6899 - loss: 0.5920 - val_accuracy: 0.6910 - val_loss: 0.5872 - learning_rate: 4.7554e-06\n",
            "Epoch 33/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 554us/step - accuracy: 0.6890 - loss: 0.5923 - val_accuracy: 0.6911 - val_loss: 0.5872 - learning_rate: 4.7554e-06\n",
            "Epoch 34/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 598us/step - accuracy: 0.6892 - loss: 0.5923 - val_accuracy: 0.6910 - val_loss: 0.5872 - learning_rate: 4.7554e-06\n",
            "Epoch 35/100\n",
            "\u001b[1m7687/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6893 - loss: 0.5921\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 556us/step - accuracy: 0.6893 - loss: 0.5921 - val_accuracy: 0.6910 - val_loss: 0.5872 - learning_rate: 4.7554e-06\n",
            "Epoch 36/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 577us/step - accuracy: 0.6896 - loss: 0.5922 - val_accuracy: 0.6909 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 37/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 567us/step - accuracy: 0.6896 - loss: 0.5917 - val_accuracy: 0.6910 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 38/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 577us/step - accuracy: 0.6890 - loss: 0.5919 - val_accuracy: 0.6912 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 39/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 557us/step - accuracy: 0.6898 - loss: 0.5917 - val_accuracy: 0.6911 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 40/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 580us/step - accuracy: 0.6895 - loss: 0.5918 - val_accuracy: 0.6912 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 41/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 556us/step - accuracy: 0.6903 - loss: 0.5912 - val_accuracy: 0.6911 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 42/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 544us/step - accuracy: 0.6902 - loss: 0.5916 - val_accuracy: 0.6911 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 43/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 594us/step - accuracy: 0.6896 - loss: 0.5920 - val_accuracy: 0.6912 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 44/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 610us/step - accuracy: 0.6892 - loss: 0.5922 - val_accuracy: 0.6911 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 45/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 599us/step - accuracy: 0.6890 - loss: 0.5925 - val_accuracy: 0.6911 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 46/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 580us/step - accuracy: 0.6894 - loss: 0.5918 - val_accuracy: 0.6911 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 47/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 599us/step - accuracy: 0.6892 - loss: 0.5924 - val_accuracy: 0.6911 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 607us/step - accuracy: 0.6894 - loss: 0.5922 - val_accuracy: 0.6911 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 561us/step - accuracy: 0.6896 - loss: 0.5920 - val_accuracy: 0.6910 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 565us/step - accuracy: 0.6895 - loss: 0.5918 - val_accuracy: 0.6912 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 599us/step - accuracy: 0.6889 - loss: 0.5923 - val_accuracy: 0.6909 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 625us/step - accuracy: 0.6900 - loss: 0.5918 - val_accuracy: 0.6910 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 612us/step - accuracy: 0.6897 - loss: 0.5919 - val_accuracy: 0.6911 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 611us/step - accuracy: 0.6891 - loss: 0.5919 - val_accuracy: 0.6910 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 576us/step - accuracy: 0.6894 - loss: 0.5919 - val_accuracy: 0.6911 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 607us/step - accuracy: 0.6892 - loss: 0.5923 - val_accuracy: 0.6910 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 605us/step - accuracy: 0.6891 - loss: 0.5920 - val_accuracy: 0.6910 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 577us/step - accuracy: 0.6894 - loss: 0.5919 - val_accuracy: 0.6912 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 609us/step - accuracy: 0.6893 - loss: 0.5924 - val_accuracy: 0.6912 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 573us/step - accuracy: 0.6898 - loss: 0.5917 - val_accuracy: 0.6911 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 623us/step - accuracy: 0.6905 - loss: 0.5912 - val_accuracy: 0.6910 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 607us/step - accuracy: 0.6889 - loss: 0.5925 - val_accuracy: 0.6910 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 619us/step - accuracy: 0.6894 - loss: 0.5920 - val_accuracy: 0.6910 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 617us/step - accuracy: 0.6893 - loss: 0.5920 - val_accuracy: 0.6911 - val_loss: 0.5872 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 598us/step - accuracy: 0.6896 - loss: 0.5918 - val_accuracy: 0.6911 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 573us/step - accuracy: 0.6899 - loss: 0.5914 - val_accuracy: 0.6911 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 580us/step - accuracy: 0.6898 - loss: 0.5916 - val_accuracy: 0.6911 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m7696/7696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 576us/step - accuracy: 0.6895 - loss: 0.5920 - val_accuracy: 0.6911 - val_loss: 0.5871 - learning_rate: 1.0000e-06\n",
            "\u001b[1m14894/14894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154us/step\n",
            "\u001b[1m14894/14894\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154us/step\n",
            "\n",
            "Resultados para el modelo neuronal (Optuna + RandomOverSampler):\n",
            "Mejores hiperparámetros: {'n_neurons_1': 46, 'n_neurons_2': 57, 'dropout_1': 0.433285768290593, 'dropout_2': 0.447831136640483, 'learning_rate': 0.0001188851883982773}\n",
            "AUC: 0.6957\n",
            "F1-score: 0.4391\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.92    422179\n",
            "           1       0.42      0.46      0.44     54408\n",
            "\n",
            "    accuracy                           0.87    476587\n",
            "   macro avg       0.67      0.69      0.68    476587\n",
            "weighted avg       0.87      0.87      0.87    476587\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_ros_train, X_ros_val, y_ros_train, y_ros_val = train_test_split(\n",
        "        X_train_ros, y_train_ros, test_size=0.2, stratify=y_train_ros, random_state=42\n",
        "    )\n",
        "\n",
        "# Mejores hiperparámetros encontrados por Optuna\n",
        "best_params = {\n",
        "    'n_neurons_1': 46,\n",
        "    'n_neurons_2': 57,\n",
        "    'dropout_1': 0.433285768290593,\n",
        "    'dropout_2': 0.447831136640483,\n",
        "    'learning_rate': 0.0001188851883982773\n",
        "}\n",
        "\n",
        "# Reconstrucción del modelo\n",
        "final_model = Sequential([\n",
        "    Input(shape=(X_train_ros.shape[1],)),\n",
        "    Dense(best_params['n_neurons_1'], activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(best_params['dropout_1']),\n",
        "    Dense(best_params['n_neurons_2'], activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(best_params['dropout_2']),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilación\n",
        "optimizer = Adam(learning_rate=best_params['learning_rate'])\n",
        "final_model.compile(optimizer=optimizer,\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Entrenamiento\n",
        "final_model.fit(\n",
        "    X_train_ros, y_train_ros,\n",
        "    validation_data=(X_ros_val, y_ros_val),\n",
        "    epochs=100,\n",
        "    batch_size=256,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluación\n",
        "y_pred_test = (final_model.predict(X_test) > 0.5).astype(int).flatten()\n",
        "y_proba_test = final_model.predict(X_test).flatten()\n",
        "\n",
        "print(\"\\nResultados para el modelo neuronal (Optuna + RandomOverSampler):\")\n",
        "print(f\"Mejores hiperparámetros: {best_params}\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_test):.4f}\")\n",
        "print(classification_report(y_test, y_pred_test))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
